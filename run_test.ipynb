{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified by @engelberger from the Colab notebook of Brian Naughton @btnaughton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_id = '' #@param {type:\"string\"}\n",
    "SMILES_or_pubchem_id = '' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "from random import random\n",
    "\n",
    "def download_pdb_file(pdb_id: str) -> str:\n",
    "    \"\"\"Download pdb file as a string from rcsb.org\"\"\"\n",
    "    PDB_DIR =\"./tmp/pdb/\"\n",
    "    os.makedirs(PDB_DIR, exist_ok=True)\n",
    "\n",
    "    # url or pdb_id\n",
    "    if pdb_id.startswith('http'):\n",
    "        url = pdb_id\n",
    "        filename = url.split('/')[-1]\n",
    "    else:\n",
    "        url = f\"http://files.rcsb.org/view/{pdb_id}.pdb\"\n",
    "        filename = f'{pdb_id}.pdb'\n",
    "\n",
    "    cache_path = os.path.join(PDB_DIR, filename)\n",
    "    if os.path.exists(cache_path):\n",
    "        return cache_path\n",
    "\n",
    "    pdb_req = requests.get(url)\n",
    "    pdb_req.raise_for_status()\n",
    "    open(cache_path, 'w').write(pdb_req.text)\n",
    "    return cache_path\n",
    "\n",
    "def download_smiles_str(pubchem_id: str, retries:int = 2) -> str:\n",
    "    \"\"\"Given a pubchem id, get a smiles string\"\"\"\n",
    "    while True:\n",
    "        req = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/CID/{pubchem_id}/property/CanonicalSMILES/CSV\")\n",
    "        smiles_url_csv = req.text if req.status_code == 200 else None\n",
    "        if smiles_url_csv is not None:\n",
    "            break\n",
    "        if retries == 0:\n",
    "            return None\n",
    "        time.sleep(1+random())\n",
    "        retries -= 1\n",
    "\n",
    "    return smiles_url_csv.splitlines()[1].split(',')[1].strip('\"').strip(\"'\") if smiles_url_csv is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No input supplied. Using example data: 6agt and COc(cc1)ccc1C#N\n"
     ]
    }
   ],
   "source": [
    "if not PDB_id or not SMILES_or_pubchem_id:\n",
    "    PDB_id = \"6agt\"\n",
    "    SMILES_or_pubchem_id = \"COc(cc1)ccc1C#N\"\n",
    "    print(f\"No input supplied. Using example data: {PDB_id} and {SMILES_or_pubchem_id}\")\n",
    "# to run many PDB+smiles at once, fill in a list of PDB_files and smiles here...\n",
    "pdb_files = [download_pdb_file(PDB_id)]\n",
    "smiless = [download_smiles_str(SMILES_or_pubchem_id) if str(SMILES_or_pubchem_id).isnumeric() else SMILES_or_pubchem_id]\n",
    "\n",
    "with open(\"./tmp/input_protein_ligand.csv\", 'w') as out:\n",
    "    out.write(\"protein_path,ligand\\n\")\n",
    "    for pdb_file in pdb_files:\n",
    "        for smiles in smiless:\n",
    "            out.write(f\"{pdb_file},{smiles}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: torch_sparse-0.6.12-cp39-cp39-linux_x86_64.whl\n",
      "Requirement already satisfied: torch-sparse==0.6.12 in /usr/local/lib/python3.8/dist-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse==0.6.12) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse==0.6.12) (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-sparse==0.6.12 -f torch_sparse-0.6.12-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.9.1+cu111.html\n",
      "Requirement already satisfied: torch-sparse==0.6.12 in /usr/local/lib/python3.8/dist-packages (0.6.12)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse==0.6.12) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse==0.6.12) (1.22.4)\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.9.1+cu111.html\n",
      "Requirement already satisfied: torch-scatter==2.0.9 in /usr/local/lib/python3.8/dist-packages (2.0.9)\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.9.1+cu111.html\n",
      "Requirement already satisfied: torch-spline-conv==1.2.1 in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.1.0.post1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-sparse==0.6.12 -f https://data.pyg.org/whl/torch-1.9.1+cu111.html\n",
    "!pip install torch-scatter==2.0.9 -f https://data.pyg.org/whl/torch-1.9.1+cu111.html\n",
    "!pip install torch-spline-conv==1.2.1 -f https://data.pyg.org/whl/torch-1.9.1+cu111.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nobject has no attribute sparse_csr_tensor:\n  File \"/usr/local/lib/python3.8/dist-packages/torch_sparse/tensor.py\", line 511\n            value = torch.ones(self.nnz(), dtype=dtype, device=self.device())\n    \n        return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n               ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m ModuleType\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m import_module\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloader\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Data\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhetero_data\u001b[39;00m \u001b[39mimport\u001b[39;00m HeteroData\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtemporal\u001b[39;00m \u001b[39mimport\u001b[39;00m TemporalData\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/data.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_sparse\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseTensor\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_store\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     FeatureStore,\n\u001b[1;32m     24\u001b[0m     FeatureTensorType,\n\u001b[1;32m     25\u001b[0m     TensorAttr,\n\u001b[1;32m     26\u001b[0m     _field_status,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_store\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     EDGE_LAYOUT_TO_ATTR_NAME,\n\u001b[1;32m     30\u001b[0m     EdgeAttr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     edge_tensor_type_to_adj_type,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_sparse/__init__.py:41\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDetected that PyTorch and torch_sparse were compiled with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     35\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdifferent CUDA versions. PyTorch has CUDA version \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     36\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mt_major\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mt_minor\u001b[39m}\u001b[39;00m\u001b[39m and torch_sparse has CUDA version \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     37\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmajor\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mminor\u001b[39m}\u001b[39;00m\u001b[39m. Please reinstall the torch_sparse that \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     38\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmatches your PyTorch install.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseStorage  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseTensor  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtranspose\u001b[39;00m \u001b[39mimport\u001b[39;00m t  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m narrow, __narrow_diag__  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_sparse/tensor.py:13\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_scatter\u001b[39;00m \u001b[39mimport\u001b[39;00m segment_csr\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_sparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseStorage, get_layout\n\u001b[1;32m     12\u001b[0m \u001b[39m@torch\u001b[39;49m\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript\n\u001b[0;32m---> 13\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mSparseTensor\u001b[39;49;00m(\u001b[39mobject\u001b[39;49m):\n\u001b[1;32m     14\u001b[0m     storage: SparseStorage\n\u001b[1;32m     16\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     17\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m         row: Optional[torch\u001b[39m.\u001b[39;49mTensor] \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m         trust_data: \u001b[39mbool\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     25\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:1128\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[39mif\u001b[39;00m _rcb \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1127\u001b[0m         _rcb \u001b[39m=\u001b[39m _jit_internal\u001b[39m.\u001b[39mcreateResolutionCallbackFromFrame(_frames_up \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1128\u001b[0m     _compile_and_register_class(obj, _rcb, qualified_name)\n\u001b[1;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m   1130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[39m# this is a decorated fn, and we need to the underlying fn and its rcb\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:138\u001b[0m, in \u001b[0;36m_compile_and_register_class\u001b[0;34m(obj, rcb, qualified_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m ast \u001b[39m=\u001b[39m get_jit_class_def(obj, obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    137\u001b[0m defaults \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mfrontend\u001b[39m.\u001b[39mget_default_args_for_class(obj)\n\u001b[0;32m--> 138\u001b[0m script_class \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_script_class_compile(qualified_name, ast, defaults, rcb)\n\u001b[1;32m    139\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39m_add_script_class(obj, script_class)\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m script_class\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nobject has no attribute sparse_csr_tensor:\n  File \"/usr/local/lib/python3.8/dist-packages/torch_sparse/tensor.py\", line 511\n            value = torch.ones(self.nnz(), dtype=dtype, device=self.device())\n    \n        return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n               ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /miniconda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-cluster\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-22.9.0               |   py39h06a4308_0         884 KB\n",
      "    cudatoolkit-11.3.1         |       h2bc3f7f_2       549.3 MB\n",
      "    ninja-1.10.2               |       h06a4308_5           8 KB\n",
      "    ninja-base-1.10.2          |       hd09550d_5         109 KB\n",
      "    pytorch-1.10.2             |cpu_py39hfa7516b_0        44.1 MB\n",
      "    pytorch-cluster-1.6.0      |py39_torch_1.10.0_cu113         1.8 MB  pyg\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       596.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-11.3.1-h2bc3f7f_2\n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5\n",
      "  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.10.2-cpu_py39hfa7516b_0\n",
      "  pytorch-cluster    pyg/linux-64::pytorch-cluster-1.6.0-py39_torch_1.10.0_cu113\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.12.0-py39h06a4308_0 --> 22.9.0-py39h06a4308_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pytorch-cluster-1.6. | 1.8 MB    | ##################################### | 100% \n",
      "ninja-1.10.2         | 8 KB      | ##################################### | 100% \n",
      "cudatoolkit-11.3.1   | 549.3 MB  | ##################################### | 100% \n",
      "conda-22.9.0         | 884 KB    | ##################################### | 100% \n",
      "pytorch-1.10.2       | 44.1 MB   | ##################################### | 100% \n",
      "ninja-base-1.10.2    | 109 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!/miniconda/bin/conda install -y pytorch-cluster -c pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Print the pytorch version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from memory:  data/cache_torsion/limit0_INDEX_maxLigSizeNone_H0_recRad15.0_recMax24_esmEmbeddings32221061/heterographs.pkl\n",
      "Number of complexes:  1\n",
      "radius protein: mean 75.19402313232422, std 0.0, max 75.19402313232422\n",
      "radius molecule: mean 3.9542152881622314, std 0.0, max 3.9542152881622314\n",
      "distance protein-mol: mean 0.8058823347091675, std 0.0, max 0.8058823347091675\n",
      "rmsd matching: mean 0.0, std 0.0, max 0\n",
      "HAPPENING | confidence model uses different type of graphs than the score model. Loading (or creating if not existing) the data for the confidence model now.\n",
      "loading data from memory:  data/cache_torsion_allatoms/limit0_INDEX_maxLigSizeNone_H0_recRad15.0_recMax24_atomRad5_atomMax8_esmEmbeddings32221061/heterographs.pkl\n",
      "Number of complexes:  1\n",
      "radius protein: mean 75.19402313232422, std 0.0, max 75.19402313232422\n",
      "radius molecule: mean 3.9588654041290283, std 0.0, max 3.9588654041290283\n",
      "distance protein-mol: mean 1.3410234451293945, std 0.0, max 1.3410234451293945\n",
      "rmsd matching: mean 0.0, std 0.0, max 0\n",
      "common t schedule [1.   0.95 0.9  0.85 0.8  0.75 0.7  0.65 0.6  0.55 0.5  0.45 0.4  0.35\n",
      " 0.3  0.25 0.2  0.15 0.1  0.05]\n",
      "Size of test dataset:  1\n",
      "0it [00:00, ?it/s]/opt/conda/lib/python3.7/site-packages/e3nn/o3/_spherical_harmonics.py:82: UserWarning: FALLBACK path has been taken inside: compileCudaFusionGroup. This is an indication that codegen Failed for some reason.\n",
      "To debug try disable codegen fallback path via setting the env variable `export PYTORCH_NVFUSER_DISABLE=fallback`\n",
      "To report the issue, try enable logging via setting the envvariable ` export PYTORCH_JIT_LOG_LEVEL=manager.cpp`\n",
      " (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/jit/codegen/cuda/manager.cpp:237.)\n",
      "  sh = _spherical_harmonics(self._lmax, x[..., 0], x[..., 1], x[..., 2])\n",
      "Failed on ['./tmp/pdb/6agt.pdb____COc(cc1)ccc1C#N'] CUDA out of memory. Tried to allocate 4.93 GiB (GPU 0; 7.79 GiB total capacity; 1.04 GiB already allocated; 3.13 GiB free; 2.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "0it [00:01, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/workspaces/DiffDock/inference.py\", line 205, in <module>\n",
      "    raise e\n",
      "  File \"/workspaces/DiffDock/inference.py\", line 171, in <module>\n",
      "    batch_size=args.batch_size, no_final_step_noise=args.no_final_step_noise)\n",
      "  File \"/workspaces/DiffDock/utils/sampling.py\", line 56, in sampling\n",
      "    tr_score, rot_score, tor_score = model(complex_graph_batch)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspaces/DiffDock/models/score_model.py\", line 273, in forward\n",
      "    rec_intra_update = self.rec_conv_layers[l](rec_node_attr, rec_edge_index, rec_edge_attr_, rec_edge_sh)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/workspaces/DiffDock/models/score_model.py\", line 78, in forward\n",
      "    tp = self.tp(node_attr[edge_dst], edge_sh, self.fc(edge_attr))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 4.93 GiB (GPU 0; 7.79 GiB total capacity; 1.04 GiB already allocated; 3.13 GiB free; 2.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python -m inference \\\n",
    "    --protein_ligand_csv ./tmp/input_protein_ligand.csv \\\n",
    "        --out_dir results/user_predictions_small \\\n",
    "            --inference_steps 20 \\\n",
    "                --samples_per_complex 40 \\\n",
    "                    --batch_size 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
